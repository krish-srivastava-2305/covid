# -*- coding: utf-8 -*-
"""final project covid case study ml done by kshitiz,anurag,shubham,harshit dbda batch sep 2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOWHGRo4f21SBlDcCoBDDULfNjHqM2v3
"""

import pandas as pd
import numpy as np

#get data from api's

df1=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data1.csv')
df1

# get data from website covid19indiaorg

df1=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data1.csv')
df2=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data2.csv')
df3=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data3.csv')
df4=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data4.csv')
df5=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data5.csv')
df6=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data6.csv')
df7=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data7.csv')
df8=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data8.csv')
df9=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data9.csv')
df10=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data10.csv')
df11=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data11.csv')
df12=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data12.csv')
df13=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data13.csv')
df14=pd.read_csv('https://data.covid19india.org/csv/latest/raw_data14.csv')

# inspect any data frame
df1.info()

#check all the columns

df1.columns

df2.columns

df9.columns

df9.columns

df14.columns

# selecting relevant column in the dataset

df1=df1.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df2=df2.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df3=df3.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df4=df4.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df5=df5.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df6=df6.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df7=df7.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df8=df8.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df9=df9.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df10=df10.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df11=df11.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df12=df12.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df13=df13.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df14=df14.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df1.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]
df1.loc[:,['Num Cases','Date Announced','Age Bracket','Gender', 'Detected City', 'Detected District','Detected State','Current Status']]

#merge all the dataframe

df=df1.append([df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14])

df

#making the sperate column for day,month and year

date=df['Date Announced'].str.split('/',expand=True)

date.columns=['Day','Month','Year']

date

#Concatinate both the data frame's along axis=1

df=pd.concat([df,date],axis=1)

#save all the data in csv format

df.to_csv("Covid19Indiafinal.csv")

#final dataset

df

#data cleaning
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt

#read csv File

df=pd.read_csv("Covid19Indiafinal.csv")
df

data=df.iloc[:,1:]
data

"""# inspect the data frame"""

data.info()

# total number of missing value with sorting and percentage of data missing

round(data.isnull().sum(axis=0).sort_values(ascending=False)/len(data)*100,2)

# inspecting null value in each row
data.isnull().sum(axis=1).sort_values(ascending=False)

"""# Total covid-19 cases month wise"""

m=data[data['Current Status']=="Hospitalized"].groupby('Month')['Num Cases'].sum()

m.plot.bar()
plt.show()

# total male/female infected with cornonavirus

data.groupby('Gender')['Num Cases'].sum()

# which age group is infected most?

data.groupby('Age Bracket')['Num Cases'].sum().sort_values(ascending=False)

"""# if you are from age 30 to 40 then you have maximum chance of getting corona"""

m=data.groupby('Age Bracket')['Num Cases'].sum().sort_values(ascending=False).head(10)

m.plot.bar(figsize=(15,5))
plt.show()

"""# check the state wise total case in india"""

h=data[data['Current Status']=='Hospitalized'].groupby('Detected State')['Num Cases'].sum().sort_values(ascending=False)

h.plot.bar()
plt.show()

# how many cases Everyday?

day=data[data['Current Status']=='Hospitalized'].groupby(['Month','Day'])[['Num Cases']].sum()
day

day.unstack(level=0).plot(kind='bar',subplots=True,figsize=(15,15))
plt.show()

# just by looking at the graph you can make rough decision

# number of the people who died

data['Current Status'].unique()

data[data['Current Status']=='Deceased']['Num Cases'].sum()

data[data['Current Status']=='Deceased'].groupby('Detected State')['Num Cases'].sum().sort_values(ascending=False)

# machine learning alogrothim libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data

#predict the cases in coming days

"""![image.png](attachment:image.png)"""

day=df[df['Current Status']=='Hospitalized'].groupby(['Month','Day'])[['Num Cases']].sum() ##

len(day)

# generating the array of length from 0 too no days

x= np.arange(len(day))
x

y = day.values
y

plt.scatter(x,y)
plt.show()

x

# we have to have x in 2d array in order to use

x=x.reshape(-1,1)

newx=x[90:,:]

newy=y[90:,:]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(newx,newy,test_size=0.2,random_state=2,shuffle=False)

from sklearn.linear_model import LinearRegression
regressor= LinearRegression()
regressor.fit(x_train,y_train)

y[183]

regressor.predict([[184]])

x_train

ytrainp=regressor.predict(x_train)
ytrainp

ytestp=regressor.predict(x_test)
ytestp

# it shows negative value which shows model is not accurate

plt.scatter(x,y)
plt.plot(x_train,ytrainp,color='b')
plt.plot(x_test,ytestp,color='k')
plt.show()

regressor.score(x_test,y_test)*100

regressor.intercept_

regressor.coef_

regressor.predict([[190]])

# model metrics
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

y_pred=regressor.predict(x_test)
y_pred

y_test

# mean absolute error #advantage is 1.same unit as y unit 2.can handle outlier

print("MAE",mean_absolute_error(y_test,y_pred))

# mean squared error #advantage loss function because differenciate

print("MSE",mean_squared_error(y_test,y_pred))

# root mean squared error

print("RMSE",np.sqrt(mean_squared_error(y_test,y_pred)))

# r2 Score it tell how much better is linear regression compared to Ymean line also called goodness of fit and 
# coffiecient of determention 
# r2= 1-ssr/ssm
# higher value of r2 the better value
# it tell us certain amount variance in output column is explained by input column

print("R2score",r2_score(y_test,y_pred))

# adjusted r2 score we add more column in the input column the r2 score keep on increasing automatically even on adding 
# irrelivant column
r2 =r2_score(y_test,y_pred)

x_test.shape

1-((1-r2)*(19-1)/(19-1-1))  # 1-((1-r2)*(n-1)/(n-1-k) n=no of rows ,k= independent columns

# to increase the accurace of linear regression we can change the intervel

## import polynomial regression

# import relevant libraies

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('Covid19Indiafinal.csv')
data

day=data[data['Current Status']=="Hospitalized"].groupby(['Month','Day'])[['Num Cases']].sum()

x= np.arange(len(day))
x

y=day.values
y

x=x.reshape(-1,1)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2,shuffle=False)

from sklearn.preprocessing import PolynomialFeatures
Poly=PolynomialFeatures(degree=2)
X=Poly.fit_transform(x_train.reshape(-1,1))
X

pd.DataFrame(X)

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X,y_train)

reg.coef_

reg.intercept_

X_test=Poly.fit_transform(x_test.reshape(-1,1))

yp=reg.predict(X_test)
yp

x_test

y_test

plt.scatter(x,y)
plt.plot()
plt.plot(x_test,yp,color='k')
plt.show()

reg.predict([[1,200,40000]])

#r2 score
reg.score(X_test,y_test)*100

x

reg.predict(Poly.transform([[184]]))

# model metrics
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

# mean absolute error #advantage is 1.same unit as y unit 2.can handle outlier

print("MAE",mean_absolute_error(y_test,yp))

# mean squared error #advantage loss function because differenciate at zero

print("MSE",mean_squared_error(y_test,yp))

# root mean squared error

print("RMSE",np.sqrt(mean_squared_error(y_test,yp)))

# r2 Score it tell how much better is linear regression compared to Ymean line also called goodness of fit and 
# coffiecient of determention 
# r2= 1-ssr/ssm
# higher value of r2 the better value
# it tell us certain amount variance in output column is explained by input column

print("R2score",r2_score(y_test,yp))

# adjusted r2 score we add more column in the input column the r2 score keep on increasing automatically even on adding 
# irrelivant column
r2 =r2_score(y_test,yp)

x_test.shape

1-((1-r2)*(37-1)/(37-1-1))  # 1-((1-r2)*(n-1)/(n-1-k) n=no of rows ,k= independent columns

# degree 5 polyregression model

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('Covid19Indiafinal.csv')
data

day=data[data['Current Status']=="Hospitalized"].groupby(['Month','Day'])[['Num Cases']].sum()

x= np.arange(len(day))
x

y=day.values
y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=2,shuffle=False)

x_train

from sklearn.preprocessing import PolynomialFeatures
Poly=PolynomialFeatures(degree=3)
X=Poly.fit_transform(x_train.reshape(-1,1))
X



from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X,y_train)

reg.coef_

reg.intercept_

X_test=Poly.fit_transform(x_test.reshape(-1,1))

yp=reg.predict(X_test)
yp

plt.scatter(x,y)
plt.plot(x_test,yp,color='k')
plt.show()

#r2 score
reg.score(X_test,y_test)*100

reg.predict(Poly.transform([[184]]))

# model metrics
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

# mean absolute error #advantage is 1.same unit as y unit 2.can handle outlier

print("MAE",mean_absolute_error(y_test,yp))

# mean squared error #advantage loss function because differenciate

print("MSE",mean_squared_error(y_test,yp))

# root mean squared error

print("RMSE",np.sqrt(mean_squared_error(y_test,yp)))

# r2 Score it tell how much better is linear regression compared to Ymean line also called goodness of fit and 
# coffiecient of determention 
# r2= 1-ssr/ssm
# higher value of r2 the better value
# it tell us certain amount variance in output column is explained by input column

print("R2score",r2_score(y_test,yp))

# adjusted r2 score we add more column in the input column the r2 score keep on increasing automatically even on adding 
# irrelivant column
r2 =r2_score(y_test,yp)

x_test.shape

1-((1-r2)*(56-1)/(56-1-1))  # 1-((1-r2)*(n-1)/(n-1-k) n=no of rows ,k= independent columns

#support vector regression

# import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv("Covid19Indiafinal.csv")

# kernel :-> rbf  radial bias function curve is semi circle 180 degree from zero

from sklearn import svm

day=data[data['Current Status']=='Hospitalized'].groupby(['Month','Day'])[['Num Cases']].sum()
day

x=np.arange(len(day))
x

y=day.values
y

# when we use svr we have standardize the data

x=x.reshape(-1,1)
y=y.reshape(-1,1)

from sklearn.preprocessing import StandardScaler
sc_x=StandardScaler()
sc_y=StandardScaler()
sx=sc_x.fit_transform(x)
sy=sc_y.fit_transform(y)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(sx,sy,test_size=0.2,random_state=2,shuffle=False)

# Building the SVM model
from sklearn.model_selection import RandomizedSearchCV, train_test_split
kernel = ['poly', 'sigmoid', 'rbf']
c = [0.01, 0.1, 1, 10]
gamma = [0.01, 0.1, 1]
epsilon = [0.01, 0.1, 1]
shrinking = [True, False]
svm_grid = {'kernel': kernel, 'C': c, 'gamma' : gamma, 'epsilon': epsilon, 'shrinking' : shrinking}

svm = svm.SVR()
svm_search = RandomizedSearchCV(svm, svm_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, 
                                n_iter=40, verbose=1)
svm_search.fit(x_train,y_train.ravel())

svm_search.best_params_

svm_confirmed = svm_search.best_estimator_
svm_pred = svm_confirmed.predict(x_test)

svm_confirmed

svm_pred

# ravel converts 2d array to one dimension array

plt.scatter(sx,sy)
plt.scatter(x_test,svm_pred,color='k')
plt.show()

# model metrics
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
# mean absolute error #advantage is 1.same unit as y unit 2.can handle outlier

print("MAE",mean_absolute_error(y_test,svm_pred))

# mean squared error #advantage loss function because differenciate
print("MSE",mean_squared_error(y_test,svm_pred))

# root mean squared error 
print("RMSE",np.sqrt(mean_squared_error(y_test,svm_pred)))

y_test,svm_pred

# r2 Score it tell how much better is linear regression compared to Ymean line also called goodness of fit and 
# coffiecient of determention 
# r2= 1-ssr/ssm
# higher value of r2 the better value
# it tell us certain amount variance in output column is explained by input column
print("R2score",r2_score(y_test,svm_pred))

# adjusted r2 score we add more column in the input column the r2 score keep on increasing automatically even on adding 
# irrelivant column
r2 =r2_score(y_test,svm_pred)
x_test.shape

1-((1-r2)*(37-1)/(37-1-1))  # 1-((1-r2)*(n-1)/(n-1-k) n=no of rows ,k= independent columns

#Decision tree regression

# when data is non linear in nature we use decison and random forest

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('Covid19Indiafinal.csv')

data

data=data.iloc[:,1:]

"""![image-2.png](attachment:image-2.png)

![image.png](attachment:image.png)
"""

#it will split the data as per certain  condition

day=data[data['Current Status']=='Hospitalized'].groupby(['Month','Day'])[['Num Cases']].sum()

x=np.arange(len(day))
x=x.reshape(-1,1)
x

y=day.values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2,shuffle=False)

from sklearn.tree import DecisionTreeRegressor
reg= DecisionTreeRegressor()
reg.fit(x_train,y_train)

Yp=reg.predict(x_test)
Yp

plt.scatter(x,y)
plt.plot(x_train,reg.predict(x_train),color='r')
plt.plot(x_test,Yp,color='k')
plt.show()

reg.score(x_test,y_test)*100

reg.predict([[184]])

y[183]

reg.predict([[189]])

# this due to overfiting of data this problem commonly ocuurs with decision tree

# random forest regression

# import libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as ply

data = pd.read_csv('Covid19Indiafinal.csv')

data=data.iloc[:,1:]

data

"""![image.png](attachment:image.png)"""

day=data[data["Current Status"]=="Hospitalized"].groupby(["Month","Day"])[['Num Cases']].sum()
day

x=np.arange(len(day))
x=x.reshape(-1,1)
y=day.values

y

y.ravel()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2,shuffle=False)

from sklearn.ensemble import RandomForestRegressor
reg = RandomForestRegressor(n_estimators=100)#by default 300 tree
reg.fit(x_train,y_train.ravel())

reg.score(x_test,y_test)*100

plt.scatter(x,y)
plt.plot(x_train,reg.predict(x_train),color='r')
plt.plot(x_test,reg.predict(x_test),color='k')
plt.show()

reg.predict([[184]])

reg.predict([[185]])

reg.predict([[189]])

reg.predict([[194]])
#badhia hai!

# here also problem of overfittinng is ocuuring we have use this model when your data is purely non linear in nature
